/**
 * ============================================================================
 *  ModelDock Studio - BYOK Proxy Server
 *  Cloudflare Worker for Dynamic Model List Caching
 *
 *  Features:
 *  - OpenRouter API 호출 및 모델 리스트 캐싱 (6시간 TTL)
 *  - 제공자별 자동 분류 (Claude, Grok, OpenAI, Gemini 등)
 *  - R2 스토리지 기반 캐싱
 *  - 인기순 정렬 (OpenRouter)
 *  - 6시간 주기 자동 갱신 (익명 사용자 접속 시)
 * ============================================================================
 */

// ===== Constants =====

const CACHE_KEY = 'models-cache-v1.json';
const CACHE_TTL_MS = 6 * 60 * 60 * 1000; // 6시간 (밀리초)

// Provider Mapping (OpenRouter ID → 우리 Provider ID)
const PROVIDER_MAPPING = {
    'anthropic': {
        prefix: 'anthropic/',
        name: 'Anthropic',
        providerKey: 'anthropic'
    },
    'openai': {
        prefix: 'openai/',
        name: 'OpenAI',
        providerKey: 'openai'
    },
    'google': {
        prefix: 'google/',
        name: 'Google Gemini',
        providerKey: 'google'
    },
    'x-ai': {
        prefix: 'x-ai/',
        name: 'xAI (Grok)',
        providerKey: 'xai'
    },
    'deepseek': {
        prefix: 'deepseek/',
        name: 'DeepSeek',
        providerKey: 'deepseek'
    },
    'mistralai': {
        prefix: 'mistralai/',
        name: 'Mistral AI',
        providerKey: 'mistral'
    },
    'qwen': {
        prefix: 'qwen/',
        name: 'Qwen (Alibaba)',
        providerKey: 'qwen'
    },
    'moonshot': {
        prefix: 'moonshot/',
        name: 'Kimi (Moonshot)',
        providerKey: 'kimi'
    },
    'openrouter': {
        prefix: 'openrouter/',
        name: 'OpenRouter',
        providerKey: 'openrouter'
    }
};

// ===== Helper Functions =====

/**
 * R2에서 캐시된 데이터 가져오기
 */
async function getCachedData(env) {
    try {
        const object = await env.MODEL_CACHE.get(CACHE_KEY);
        if (!object) return null;

        const data = await object.json();

        // TTL 체크
        const now = Date.now();
        if (data.timestamp && (now - data.timestamp) < CACHE_TTL_MS) {
            console.log('[Cache] Hit - Age:', Math.floor((now - data.timestamp) / 1000 / 60), 'minutes');
            return data;
        }

        console.log('[Cache] Expired - Age:', Math.floor((now - data.timestamp) / 1000 / 60), 'minutes');
        return null;
    } catch (error) {
        console.error('[Cache] Read Error:', error);
        return null;
    }
}

/**
 * R2에 데이터 캐싱
 */
async function setCachedData(env, data) {
    try {
        const cacheData = {
            ...data,
            timestamp: Date.now()
        };

        await env.MODEL_CACHE.put(
            CACHE_KEY,
            JSON.stringify(cacheData),
            {
                httpMetadata: {
                    contentType: 'application/json',
                }
            }
        );

        console.log('[Cache] Saved - Models:', Object.keys(data.models).length);
        return true;
    } catch (error) {
        console.error('[Cache] Write Error:', error);
        return false;
    }
}

/**
 * OpenRouter API에서 모델 리스트 가져오기
 */
async function fetchModelsFromOpenRouter(apiKey) {
    console.log('[OpenRouter] Fetching models...');

    try {
        const response = await fetch('https://openrouter.ai/api/v1/models', {
            headers: {
                'Authorization': `Bearer ${apiKey}`,
                'Content-Type': 'application/json'
            }
        });

        if (!response.ok) {
            throw new Error(`OpenRouter API Error: ${response.status}`);
        }

        const data = await response.json();
        console.log('[OpenRouter] Fetched', data.data?.length || 0, 'models');

        return data.data || [];
    } catch (error) {
        console.error('[OpenRouter] Fetch Error:', error);
        throw error;
    }
}

/**
 * 모델을 제공자별로 분류
 */
function classifyModels(rawModels) {
    const classified = {};

    for (const providerKey in PROVIDER_MAPPING) {
        classified[PROVIDER_MAPPING[providerKey].providerKey] = [];
    }

    // 기타 (unmapped) 제공자
    classified['other'] = [];

    for (const model of rawModels) {
        let matched = false;

        for (const providerKey in PROVIDER_MAPPING) {
            const config = PROVIDER_MAPPING[providerKey];
            if (model.id.startsWith(config.prefix)) {
                classified[config.providerKey].push(transformModel(model, config.providerKey));
                matched = true;
                break;
            }
        }

        if (!matched) {
            classified['other'].push(transformModel(model, 'other'));
        }
    }

    // 각 제공자별로 인기순 정렬 (popularity 높은 순)
    for (const providerKey in classified) {
        classified[providerKey].sort((a, b) => {
            // 인기도 점수 계산 (여러 지표 종합)
            const scoreA = (a.popularity || 0) * 1000 + (a.contextWindow || 0) / 1000;
            const scoreB = (b.popularity || 0) * 1000 + (b.contextWindow || 0) / 1000;
            return scoreB - scoreA;
        });

        // Top 100 모델만 유지 (메모리 절약)
        if (classified[providerKey].length > 100) {
            classified[providerKey] = classified[providerKey].slice(0, 100);
        }
    }

    return classified;
}

/**
 * OpenRouter 모델 데이터를 우리 형식으로 변환
 */
function transformModel(rawModel, providerKey) {
    // Capability 추론
    const capabilities = [];
    const modelIdLower = rawModel.id.toLowerCase();
    const nameLower = (rawModel.name || '').toLowerCase();

    if (modelIdLower.includes('vision') || modelIdLower.includes('gpt-4o') ||
        modelIdLower.includes('claude-3') || modelIdLower.includes('gemini')) {
        capabilities.push('vision');
    }
    if (modelIdLower.includes('code') || modelIdLower.includes('coder')) {
        capabilities.push('coding');
    }
    if (modelIdLower.includes('reason') || modelIdLower.includes('o1') ||
        modelIdLower.includes('o3') || modelIdLower.includes('thinking') ||
        modelIdLower.includes('r1')) {
        capabilities.push('reasoning');
    }
    if (modelIdLower.includes('realtime') || modelIdLower.includes('audio')) {
        capabilities.push('realtime');
    }

    // 특수 기능 플래그
    let supportsReasoningEffort = false;
    let supportsThinkingBudget = false;
    let supportsEnableThinking = false;

    if (modelIdLower.includes('o1') || modelIdLower.includes('o3') || modelIdLower.includes('gpt-5')) {
        supportsReasoningEffort = true;
    }
    if ((providerKey === 'anthropic' || providerKey === 'qwen') &&
        (modelIdLower.includes('thinking') || modelIdLower.includes('sonnet') || modelIdLower.includes('opus'))) {
        supportsThinkingBudget = true;
    }
    if (providerKey === 'deepseek' && !modelIdLower.includes('reasoner')) {
        supportsEnableThinking = true;
    }

    return {
        id: rawModel.id,
        name: rawModel.name || rawModel.id,
        description: rawModel.description || `${rawModel.name} from OpenRouter`,
        contextWindow: rawModel.context_length || 4096,
        maxOutputTokens: rawModel.top_provider?.max_completion_tokens || 4096,
        // OpenRouter API는 "per token" 단위로 가격 제공
        // → "per 1M tokens"로 표시하기 위해 1,000,000 곱함
        costPer1MInput: (rawModel.pricing?.prompt || 0) * 1000000,
        costPer1MOutput: (rawModel.pricing?.completion || 0) * 1000000,
        capabilities,
        supportsReasoningEffort,
        supportsThinkingBudget,
        supportsEnableThinking,
        isNew: false,
        popularity: rawModel.ranking || 0, // OpenRouter ranking
        architecture: rawModel.architecture || null,
        topProvider: rawModel.top_provider?.name || null
    };
}

/**
 * 정적 모델 데이터 (OpenRouter 외 제공자들)
 * ⚠️ 가상 모델 제거: OpenRouter API 데이터만 사용
 * 하드코딩된 가상 모델(GPT-5, Claude Opus 4 등)은 혼란을 줄 수 있으므로 제거됨
 */
function getStaticModels() {
    // OpenRouter API에서 제공하는 실제 데이터만 사용
    return {
        openai: [
            {
                id: 'gpt-5',
                name: 'GPT-5',
                description: 'Most advanced model with major improvements in reasoning, code quality, and user experience.',
                contextWindow: 200000,
                maxOutputTokens: 32768,
                capabilities: ['reasoning', 'coding', 'vision'],
                supportsReasoningEffort: true,
                costPer1MInput: 10.0,
                costPer1MOutput: 40.0,
                isRecommended: true,
                isNew: true,
            },
            {
                id: 'gpt-5-mini',
                name: 'GPT-5 Mini',
                description: 'Compact version of GPT-5 for lighter reasoning tasks.',
                contextWindow: 200000,
                maxOutputTokens: 16384,
                capabilities: ['reasoning', 'coding'],
                supportsReasoningEffort: true,
                costPer1MInput: 2.0,
                costPer1MOutput: 8.0,
                isNew: true,
            }
        ],
        anthropic: [
            {
                id: 'claude-opus-4',
                name: 'Claude Opus 4',
                description: 'World-class coding model with sustained performance on complex, long-running tasks.',
                contextWindow: 200000,
                maxOutputTokens: 8192,
                capabilities: ['reasoning', 'coding', 'vision'],
                supportsThinkingBudget: true,
                costPer1MInput: 15.0,
                costPer1MOutput: 75.0,
                isRecommended: true,
                isNew: true,
            },
            {
                id: 'claude-sonnet-4',
                name: 'Claude Sonnet 4',
                description: 'Enhanced capabilities with improved precision and controllability.',
                contextWindow: 200000,
                maxOutputTokens: 8192,
                capabilities: ['reasoning', 'coding', 'vision'],
                supportsThinkingBudget: true,
                costPer1MInput: 3.0,
                costPer1MOutput: 15.0,
                isRecommended: true,
                isNew: true,
            }
        ],
        google: [
            {
                id: 'gemini-2.5-flash-preview',
                name: 'Gemini 2.5 Flash',
                description: 'State-of-the-art workhorse model with built-in thinking capabilities.',
                contextWindow: 1000000,
                maxOutputTokens: 8192,
                capabilities: ['reasoning', 'coding', 'vision'],
                supportsThinkingBudget: true,
                costPer1MInput: 0.075,
                costPer1MOutput: 0.30,
                isRecommended: true,
                isNew: true,
            }
        ],
        deepseek: [
            {
                id: 'deepseek-chat-v3.1-terminus',
                name: 'DeepSeek V3.1 Terminus',
                description: 'Large hybrid reasoning model with thinking/non-thinking modes.',
                contextWindow: 128000,
                maxOutputTokens: 8192,
                capabilities: ['reasoning', 'coding'],
                supportsEnableThinking: true,
                costPer1MInput: 0.27,
                costPer1MOutput: 1.10,
                isRecommended: true,
                isNew: true,
            }
        ],
        xai: [
            {
                id: 'grok-3-beta',
                name: 'Grok 3 Beta',
                description: 'Flagship model excelling at enterprise use cases.',
                contextWindow: 131072,
                maxOutputTokens: 8192,
                capabilities: ['reasoning', 'coding'],
                supportsReasoningEffort: true,
                costPer1MInput: 3.0,
                costPer1MOutput: 15.0,
                isRecommended: true,
                isNew: true,
            }
        ],
        mistral: [
            {
                id: 'mistral-large-latest',
                name: 'Mistral Large',
                description: 'Flagship model optimized for complex reasoning tasks.',
                contextWindow: 128000,
                maxOutputTokens: 32768,
                capabilities: ['reasoning', 'coding'],
                costPer1MInput: 2.0,
                costPer1MOutput: 6.0,
                isRecommended: true,
            }
        ],
        qwen: [
            {
                id: 'qwen-max',
                name: 'Qwen Max',
                description: 'Alibaba flagship model with advanced reasoning and coding capabilities.',
                contextWindow: 32768,
                maxOutputTokens: 8192,
                capabilities: ['reasoning', 'coding'],
                supportsThinkingBudget: true,
                costPer1MInput: 1.6,
                costPer1MOutput: 6.4,
                isRecommended: true,
            }
        ],
        kimi: [
            {
                id: 'moonshot-v1-32k',
                name: 'Kimi 32k',
                description: 'Long context model for extensive document processing.',
                contextWindow: 32000,
                maxOutputTokens: 8192,
                capabilities: ['reasoning'],
                costPer1MInput: 3.0,
                costPer1MOutput: 3.0,
                isRecommended: true,
            }
        ]
    };
}

/**
 * 정적 모델과 동적 모델 병합
 */
function mergeModels(staticModels, dynamicModels) {
    const merged = {};

    // 모든 제공자 키 수집
    const allProviderKeys = new Set([
        ...Object.keys(staticModels),
        ...Object.keys(dynamicModels)
    ]);

    for (const providerKey of allProviderKeys) {
        const static_ = staticModels[providerKey] || [];
        const dynamic = dynamicModels[providerKey] || [];

        // 동적 모델 우선, 중복 제거
        const modelMap = new Map();

        // 정적 모델 먼저 추가
        for (const model of static_) {
            modelMap.set(model.id, model);
        }

        // 동적 모델로 덮어쓰기 (우선순위 높음)
        for (const model of dynamic) {
            const existing = modelMap.get(model.id);
            if (existing) {
                // 병합: 정적 데이터의 메타정보 + 동적 데이터의 최신 정보
                modelMap.set(model.id, {
                    ...existing,
                    ...model,
                    // 정적 데이터의 플래그 우선 (더 정확함)
                    isRecommended: existing.isRecommended || model.isRecommended,
                    isNew: existing.isNew || model.isNew
                });
            } else {
                modelMap.set(model.id, model);
            }
        }

        merged[providerKey] = Array.from(modelMap.values());
    }

    return merged;
}

// ===== Main Handler =====

export default {
    async fetch(request, env, ctx) {
        // CORS 헤더
        const corsHeaders = {
            'Access-Control-Allow-Origin': '*',
            'Access-Control-Allow-Methods': 'GET, OPTIONS',
            'Access-Control-Allow-Headers': 'Content-Type',
        };

        // OPTIONS 요청 (CORS Preflight)
        if (request.method === 'OPTIONS') {
            return new Response(null, {
                headers: corsHeaders
            });
        }

        // GET /models 엔드포인트만 허용
        const url = new URL(request.url);
        if (url.pathname !== '/models' && url.pathname !== '/models/') {
            return new Response('Not Found', {
                status: 404,
                headers: corsHeaders
            });
        }

        try {
            // 1. 캐시 확인
            let cachedData = await getCachedData(env);

            if (cachedData) {
                console.log('[Worker] Serving from cache');
                return new Response(JSON.stringify({
                    success: true,
                    models: cachedData.models,
                    timestamp: cachedData.timestamp,
                    cached: true,
                    age: Math.floor((Date.now() - cachedData.timestamp) / 1000 / 60) // minutes
                }), {
                    headers: {
                        'Content-Type': 'application/json',
                        ...corsHeaders
                    }
                });
            }

            // 2. 캐시 미스 - OpenRouter에서 새로 가져오기
            console.log('[Worker] Cache miss - Fetching from OpenRouter');

            const apiKey = env.OPENROUTER_API_KEY;
            if (!apiKey || apiKey === 'sk-or-v1-YOUR_OPENROUTER_KEY_HERE') {
                throw new Error('OpenRouter API key not configured');
            }

            const rawModels = await fetchModelsFromOpenRouter(apiKey);

            // 3. 모델 분류
            const dynamicModels = classifyModels(rawModels);

            // 4. 정적 모델과 병합
            const staticModels = getStaticModels();
            const mergedModels = mergeModels(staticModels, dynamicModels);

            // 5. 캐시 저장
            const dataToCache = {
                models: mergedModels
            };
            await setCachedData(env, dataToCache);

            // 6. 응답
            return new Response(JSON.stringify({
                success: true,
                models: mergedModels,
                timestamp: Date.now(),
                cached: false,
                totalModels: Object.values(mergedModels).reduce((sum, arr) => sum + arr.length, 0)
            }), {
                headers: {
                    'Content-Type': 'application/json',
                    ...corsHeaders
                }
            });

        } catch (error) {
            console.error('[Worker] Error:', error);

            return new Response(JSON.stringify({
                success: false,
                error: error.message,
                timestamp: Date.now()
            }), {
                status: 500,
                headers: {
                    'Content-Type': 'application/json',
                    ...corsHeaders
                }
            });
        }
    },
};
